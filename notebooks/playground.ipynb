{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     0     0     0\n",
      "1     0     0     0\n",
      "2     1    10   100\n",
      "3     2    20   200\n",
      "4     3    30   300\n",
      "5     4    40   400\n",
      "6     5    50   500\n",
      "7     0     0     0\n",
      "8     0     0     0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def zero_pad_dataframe(df, num_pad_rows):\n",
    "    # Create a DataFrame with the desired number of rows filled with zeros\n",
    "    zero_pad_data = {\n",
    "        col: [0] * num_pad_rows for col in df.columns\n",
    "    }\n",
    "    zero_pad_df = pd.DataFrame(zero_pad_data)\n",
    "\n",
    "    # Concatenate the zero pad DataFrame before and after the original DataFrame\n",
    "    final_df = pd.concat([zero_pad_df, df, zero_pad_df], ignore_index=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Sample dataframe with 3 columns and 5 rows\n",
    "data = {\n",
    "    'col1': [1, 2, 3, 4, 5],\n",
    "    'col2': [10, 20, 30, 40, 50],\n",
    "    'col3': [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Number of additional rows to add on both sides\n",
    "num_pad_rows = 2\n",
    "\n",
    "# Zero-pad the dataframe\n",
    "padded_df = zero_pad_dataframe(df, num_pad_rows)\n",
    "    \n",
    "\n",
    "print(padded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     1     1\n",
      "1     2     2\n",
      "2     3     3\n",
      "3     4     4\n",
      "4     5     5\n",
      "   col1  col2  index_ref\n",
      "0     1     1          0\n",
      "1     3     3          2\n",
      "2     4     4          3\n",
      "3     5     5          4\n",
      "Reset index:  1\n",
      "   col1  col2  index_ref\n",
      "0     1     1          0\n",
      "1     3     3          2\n",
      "2     4     4          3\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\": [1,2,3,4,5],\n",
    "        \"col2\": [1,2,3,4,5]\n",
    "    }\n",
    ")\n",
    "print(df)\n",
    "\n",
    "df[\"index_ref\"] = df.index\n",
    "\n",
    "idx = 2\n",
    "\n",
    "df = df[df.col1 != 2].reset_index(drop=True)\n",
    "print(df)\n",
    "\n",
    "idx_filtered = df[df[\"index_ref\"] == idx].index.values[0]\n",
    "print(\"Reset index: \", idx_filtered)\n",
    "\n",
    "df_w = df.iloc[idx_filtered-1:idx_filtered+1+1]\n",
    "print(df_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Embbeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4918],\n",
      "        [ 1.7749],\n",
      "        [-0.7107],\n",
      "        [-0.0392],\n",
      "        [-0.4191],\n",
      "        [ 1.0474]], requires_grad=True)\n",
      "tensor([[1, 3],\n",
      "        [5, 5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7749],\n",
       "         [-0.0392]],\n",
       "\n",
       "        [[ 1.0474],\n",
       "         [ 1.0474]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys \n",
    "\n",
    "# Embedding Layer: \n",
    "emb = nn.Embedding(num_embeddings=6, embedding_dim=1)\n",
    "\n",
    "print(emb.weight)\n",
    "\n",
    "\n",
    "input = torch.LongTensor([[1,3], [5,5]])\n",
    "print(input)\n",
    "\n",
    "emb(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/wannerje/Documents/Digital-Assist-AI/In-Car-RecSys/Processed_data_new/01_Mf4_Extracted/SEB880_extracted_mf4.csv\")\n",
    "#df_parquet = pd.read_parquet(mf4_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for row in df.temperature_out:\n",
    "    if row == \"Init\":\n",
    "        counter += 1\n",
    "\n",
    "print((counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  1.5783e-01,  9.8747e-01,  2.5116e-02,\n",
      "          9.9968e-01,  3.9811e-03,  9.9999e-01,  6.3096e-04,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  3.1170e-01,  9.5018e-01,  5.0217e-02,\n",
      "          9.9874e-01,  7.9621e-03,  9.9997e-01,  1.2619e-03,  1.0000e+00],\n",
      "        [ 1.4112e-01, -9.8999e-01,  4.5775e-01,  8.8908e-01,  7.5285e-02,\n",
      "          9.9716e-01,  1.1943e-02,  9.9993e-01,  1.8929e-03,  1.0000e+00],\n",
      "        [-7.5680e-01, -6.5364e-01,  5.9234e-01,  8.0569e-01,  1.0031e-01,\n",
      "          9.9496e-01,  1.5924e-02,  9.9987e-01,  2.5238e-03,  1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import sys \n",
    "\n",
    "\n",
    "a = torch.arange(0,10).unsqueeze(1).expand(10,3)\n",
    "a = torch.arange(0,10).expand(4,10)\n",
    "\n",
    "seq_len, hidden_dim = (5, 10)\n",
    "\n",
    "pe = torch.zeros(seq_len, hidden_dim) # positional encoding \n",
    "pos = torch.arange(0, seq_len, dtype=torch.float32).unsqueeze(1)\n",
    "_2i = torch.arange(0, hidden_dim, step=2).float()\n",
    "pe[:, 0::2] = torch.sin(pos / (10000 ** (_2i / hidden_dim)))\n",
    "pe[:, 1::2] = torch.cos(pos / (10000 ** (_2i / hidden_dim)))\n",
    "\n",
    "print(pe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   education  color  age  target\n",
      "0          1      2   25       0\n",
      "1          0      0   30       1\n",
      "2          2      1   28       1\n",
      "3          0      2   22       0\n",
      "4          1      0   35       1\n",
      "6\n",
      "tensor([[1, 0],\n",
      "        [2, 1],\n",
      "        [1, 2],\n",
      "        [0, 2]])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([4, 2, 8])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 3 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 102\u001b[0m\n\u001b[1;32m     99\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    101\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m outputs \u001b[39m=\u001b[39m fusion_model(X_train_cat_tensor, X_train_cont_tensor)\n\u001b[1;32m    103\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, y_train_tensor)\n\u001b[1;32m    105\u001b[0m \u001b[39m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Digital-Assist-AI/In-Car-RecSys/venv-rec/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[57], line 63\u001b[0m, in \u001b[0;36mFusionModel.forward\u001b[0;34m(self, x_cat, x_cont)\u001b[0m\n\u001b[1;32m     60\u001b[0m cont_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_age(x_cont)\n\u001b[1;32m     62\u001b[0m \u001b[39m# Concatenate embeddings and continuous features\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m fused_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((emb_features, cont_features), dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     64\u001b[0m fused_features \u001b[39m=\u001b[39m fused_features\u001b[39m.\u001b[39mview(fused_features\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# Flatten\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m# Apply shared linear layer\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 3 and 2"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7500)\n",
      "tensor(0.6000)\n",
      "tensor(0.6667)\n",
      "tensor(0.5556)\n",
      "tensor([[2, 1, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Precision, F1Score, Recall, ConfusionMatrix, Accuracy\n",
    "\n",
    "pred = torch.Tensor([0,1,2,0])\n",
    "target = torch.Tensor([0,0,2,0])\n",
    "\n",
    "acc = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "f1 = F1Score(task=\"multiclass\", average=\"macro\", num_classes=3) \n",
    "precision = Precision(task=\"multiclass\", average=\"macro\", num_classes=3)\n",
    "recall = Recall(task=\"multiclass\", average=\"macro\", num_classes=3)\n",
    "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=3)\n",
    "print(acc(pred, target))\n",
    "print(f1(pred, target))\n",
    "print(precision(pred, target))\n",
    "print(recall(pred, target))\n",
    "print(confmat(pred, target))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
